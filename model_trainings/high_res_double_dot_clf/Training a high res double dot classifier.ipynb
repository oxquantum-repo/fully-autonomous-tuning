{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1DCBrpMIaqUf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import imgaug\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIvhJheocTva",
    "outputId": "b44aa3b4-5a0e-42d0-98d1-1bbdf1be1dee"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../signal_processing/utils/\")\n",
    "from training_utils import (\n",
    "    normalise_arrays,\n",
    "    binarise,\n",
    "    get_net_optimiser_scheduler_criterion,\n",
    "    StabilityDiagrams,\n",
    ")\n",
    "\n",
    "from augmentations import augment_batch, sample_simple_augmentation_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw7AjvHsha5A"
   },
   "source": [
    "# Setting a computing device for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eOgxF7cinki",
    "outputId": "ac6a1d70-6bd2-4a7e-d704-5a8e53225176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8Aa-ZSMn6qc",
    "outputId": "d7496933-3c65-4a98-e27a-b1c48a3377be"
   },
   "source": [
    "# Loading data\n",
    "\n",
    "See the notebook \"Illustration of data\" for more info on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H4RDD2xtoTzE"
   },
   "outputs": [],
   "source": [
    "root = \"../data/\"\n",
    "nw_data_path = (\n",
    "    root + \"cross_architecture_tuning_data/20210819_20201031_processed_nanowire_data\"\n",
    ")\n",
    "finfet_data_path = (\n",
    "    root + \"cross_architecture_tuning_data/20210915_20200715_processed_finFET_data.pkl\"\n",
    ")\n",
    "heterostructure_data_path = (\n",
    "    root + \"cross_architecture_tuning_data/20210915_20200625_processed_sigeHet_data.pkl\"\n",
    ")\n",
    "\n",
    "heterostructure_gaas_data_path = root + \"faster_than_human_tuning_data/current_maps.npy\"\n",
    "\n",
    "nw_bt_data_path = root + \"various_nice_nanowire_data/nanowires_cut_down_imgs.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_DoMPmKvjtKT"
   },
   "outputs": [],
   "source": [
    "with open(nw_data_path, \"rb\") as f:\n",
    "    nw_data = pickle.load(f)\n",
    "with open(finfet_data_path, \"rb\") as f:\n",
    "    finfet_data = pickle.load(f)\n",
    "with open(heterostructure_data_path, \"rb\") as f:\n",
    "    hs_data = pickle.load(f)\n",
    "\n",
    "\n",
    "hs_gaas_data = np.load(heterostructure_gaas_data_path, allow_pickle=True)\n",
    "\n",
    "nw_other_data = np.load(nw_bt_data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to reshape some of the data so it is uniform\n",
    "\n",
    "We choose 48 x 48 as our default image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_gaas_data_resized = []\n",
    "for ind, c in enumerate(hs_gaas_data):\n",
    "    c = resize(c, (48, 48), anti_aliasing=True)\n",
    "    hs_gaas_data_resized.append(c.copy())\n",
    "hs_gaas_data = np.array(hs_gaas_data_resized)\n",
    "\n",
    "\n",
    "nw_other_data_resized = []\n",
    "for ind, c in enumerate(nw_other_data):\n",
    "    c = resize(c, (48, 48), anti_aliasing=True)\n",
    "    nw_other_data_resized.append(c.copy())\n",
    "nw_other_data = np.array(nw_other_data_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depending on the data source, we need to attach labels in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIhnx4kNoPKM",
    "outputId": "246062f0-a3e2-4ea0-f390-8f18c75e43b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X's (1755, 48, 48)\n",
      "Shape of the Y's (1755,)\n",
      "Shape of the X's (157, 48, 48)\n",
      "Shape of the Y's (157,)\n",
      "Shape of the X's (637, 48, 48)\n",
      "Shape of the Y's (637,)\n",
      "Shape of the X's (2048, 48, 48)\n",
      "Shape of the Y's (2048,)\n",
      "Shape of the X's (14, 48, 48)\n",
      "Shape of the Y's (14,)\n"
     ]
    }
   ],
   "source": [
    "X_nw = np.array(nw_data[\"high_res_scan\"])\n",
    "print(\"Shape of the X's\", X_nw.shape)\n",
    "\n",
    "y_nw = np.array(nw_data[\"label\"])\n",
    "print(\"Shape of the Y's\", y_nw.shape)\n",
    "X_finfet = np.array(finfet_data[\"high_res_scan\"])\n",
    "print(\"Shape of the X's\", X_finfet.shape)\n",
    "\n",
    "y_finfet = np.array(finfet_data[\"label\"])\n",
    "print(\"Shape of the Y's\", y_finfet.shape)\n",
    "X_hs = np.array(hs_data[\"high_res_scan\"])\n",
    "print(\"Shape of the X's\", X_hs.shape)\n",
    "\n",
    "y_hs = np.array(hs_data[\"label\"])\n",
    "print(\"Shape of the Y's\", y_hs.shape)\n",
    "\n",
    "X_hs_gaas = hs_gaas_data\n",
    "print(\"Shape of the X's\", X_hs_gaas.shape)\n",
    "\n",
    "y_hs_gaas = np.load(\n",
    "    root + \"faster_than_human_tuning_data/labels.npy\", allow_pickle=True\n",
    ")\n",
    "print(\"Shape of the Y's\", y_hs_gaas.shape)\n",
    "\n",
    "\n",
    "X_nw_other = nw_other_data\n",
    "print(\"Shape of the X's\", X_nw_other.shape)\n",
    "\n",
    "y_nw_other = np.ones(len(nw_other_data))\n",
    "print(\"Shape of the Y's\", y_nw_other.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X's (4611, 48, 48)\n",
      "Shape of the X's (4611,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X_nw, X_finfet, X_hs, X_hs_gaas, X_nw_other))\n",
    "print(\"Shape of the X's\", X.shape)\n",
    "\n",
    "y = np.concatenate((y_nw, y_finfet, y_hs, y_hs_gaas, y_nw_other))\n",
    "print(\"Shape of the X's\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4fhYc5rt8Ho",
    "outputId": "48ad6125-5566-47ba-cb05-a9322710e070"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bQKX-omTC_dh"
   },
   "outputs": [],
   "source": [
    "# Now for some training hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "v432FiJQt_5d"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 128  # size of minibatches\n",
    "n_repetitions = 5\n",
    "\n",
    "n_imgs_per_epoch = 40000\n",
    "\n",
    "print_every_n_epoch = 33\n",
    "test_size = 0.1\n",
    "\n",
    "save_directory = \"training_results/20220610_high_res_dqd_classifier/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run it ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6ba6f2aa665d439dac3e5c3739997646",
      "54d8c9a16a1f4f24b03e02b5feecf246",
      "045ae99b2e6d4526ae7756da97a1257b",
      "940061db8c674f39b0e5efdac1061759",
      "52a8971b7c8946588c002a4b58ef8ab3",
      "a05de4333f2d45178e866ce5f68ca2f7",
      "2e3805f558634820aba6d365aa3f497d",
      "21318c6241ee4fca923d3e28575dd265",
      "a2ad8beaf0cd436b86fb921b33074087",
      "503564688db645eba4ea5d61374dd527",
      "ee987668e76545d189b32c56aeadf33f",
      "f84fec6c01da486e9d8d4c84f8656808",
      "32b61b082ddb484f8beef1828d17ad5b",
      "4e632beb2024409ebe5a2db857497aba",
      "f1997a9ea1bb4ef1b7b781b09dee326b",
      "8efc0d2243b447e7b6c2c45037b3bd40",
      "27b79a8c11444b3496b89d8e29aea4ff",
      "cc42c31622244a8bab98dfc447b2d20c",
      "a51bc7fd908041479b62f13db0e023e8",
      "549d601f29594b309be96c88b54b6364",
      "0d41aacd5b8f4bbe9354db9a94e9d072",
      "6667f96a66e444b58a8f9ba5c00d129c"
     ]
    },
    "id": "1XhH5v7GuJ23",
    "outputId": "4bd2149d-74b5-46ae-8770-089d518d57d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is rep 0\n",
      "x_train shape: (4149, 48, 48)\n",
      "4149 train samples\n",
      "462 test samples\n",
      "augmenting the real data this many times:  10\n",
      "# data in real training data 4149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e6088bece24897912349a158be8b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 1 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a057c4c1c1491ebd23d69e4025299b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.0198300\n",
      "learning rate now: 0.0001\n",
      "[[374  17]\n",
      " [ 14  57]]\n",
      "0.8796693202694428\n",
      "[66] loss: 0.0546277\n",
      "learning rate now: 1.0000000000000002e-06\n",
      "[[374  17]\n",
      " [ 16  55]]\n",
      "0.8655848132271893\n",
      "[99] loss: 0.0008600\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[375  16]\n",
      " [ 17  54]]\n",
      "0.8598213320845791\n",
      "[[374  17]\n",
      " [ 17  54]]\n",
      "0.8585425597060625\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "This is rep 1\n",
      "x_train shape: (4149, 48, 48)\n",
      "4149 train samples\n",
      "462 test samples\n",
      "augmenting the real data this many times:  10\n",
      "# data in real training data 4149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fc6ea9ca75456598d6d3ecbd1b482f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27015126b444624ba231e405b30112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.1025222\n",
      "learning rate now: 0.0001\n",
      "[[384  18]\n",
      " [ 13  47]]\n",
      "0.8692786069651741\n",
      "[66] loss: 0.0581503\n",
      "learning rate now: 1.0000000000000002e-07\n",
      "[[385  17]\n",
      " [ 14  46]]\n",
      "0.8621890547263682\n",
      "[99] loss: 0.0010826\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[381  21]\n",
      " [ 14  46]]\n",
      "0.8572139303482587\n",
      "[[384  18]\n",
      " [ 14  46]]\n",
      "0.8609452736318408\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "This is rep 2\n",
      "x_train shape: (4149, 48, 48)\n",
      "4149 train samples\n",
      "462 test samples\n",
      "augmenting the real data this many times:  10\n",
      "# data in real training data 4149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfe9d884cb645ec8f319039ffa3dcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1c7a80c6cc4284a8b1755bc37dcf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.0068228\n",
      "learning rate now: 1e-05\n",
      "[[364  16]\n",
      " [ 23  59]]\n",
      "0.8387034659820283\n",
      "[66] loss: 0.0017336\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[367  13]\n",
      " [ 23  59]]\n",
      "0.8426508344030809\n",
      "[99] loss: 0.0006320\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[367  13]\n",
      " [ 23  59]]\n",
      "0.8426508344030809\n",
      "[[366  14]\n",
      " [ 23  59]]\n",
      "0.8413350449293966\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "This is rep 3\n",
      "x_train shape: (4149, 48, 48)\n",
      "4149 train samples\n",
      "462 test samples\n",
      "augmenting the real data this many times:  10\n",
      "# data in real training data 4149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed17fe435cf94b7b97dce4612a1cff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb876d6378b4b8eae8acd9c5d35c3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.0189322\n",
      "learning rate now: 0.0001\n",
      "[[367  22]\n",
      " [ 17  56]]\n",
      "0.8552840088741769\n",
      "[66] loss: 0.0008564\n",
      "learning rate now: 1e-05\n",
      "[[369  20]\n",
      " [ 18  55]]\n",
      "0.8510053878930873\n",
      "[99] loss: 0.0350668\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[371  18]\n",
      " [ 19  54]]\n",
      "0.8467267669119978\n",
      "[[369  20]\n",
      " [ 18  55]]\n",
      "0.8510053878930873\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "This is rep 4\n",
      "x_train shape: (4149, 48, 48)\n",
      "4149 train samples\n",
      "462 test samples\n",
      "augmenting the real data this many times:  10\n",
      "# data in real training data 4149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c846fedccb214f0795b9791e74c699e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba06f8fdda46cbb79904e5c214a011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.0044864\n",
      "learning rate now: 1e-05\n",
      "[[376  14]\n",
      " [ 16  56]]\n",
      "0.870940170940171\n",
      "[66] loss: 0.0007958\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[377  13]\n",
      " [ 16  56]]\n",
      "0.8722222222222222\n",
      "[99] loss: 0.0006873\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[375  15]\n",
      " [ 15  57]]\n",
      "0.8766025641025641\n",
      "[[375  15]\n",
      " [ 16  56]]\n",
      "0.8696581196581197\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "for rep in range(n_repetitions):\n",
    "    print(\"This is rep\", rep)\n",
    "\n",
    "    \"\"\"\n",
    "    Data prep\n",
    "    \"\"\"\n",
    "\n",
    "    # separate data into train and test datasetes\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=rep\n",
    "    )\n",
    "    # Data preprocessing\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = normalise_arrays(x_train)\n",
    "    x_test = normalise_arrays(x_test)\n",
    "    # Scale labels to represent two clases (0,1)\n",
    "    y_train = binarise(y_train)\n",
    "    y_test = binarise(y_test)\n",
    "    # Make sure images have shape (1, 48, 48) for pytorch\n",
    "\n",
    "    x_test = np.expand_dims(x_test, 1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "    print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "    y_test_this_rep = []\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Augmentation\n",
    "    \n",
    "    This might seem a bit involved but the reason is that the \n",
    "    augmentation function augments each image in an array\n",
    "    exactly once. We therefore repeat the augmentation a couple of times, enough\n",
    "    so that we have enough data to match the ```n_imgs_per_epoch``` \n",
    "    requirement.\n",
    "    \"\"\"\n",
    "    n_augmentations = n_imgs_per_epoch // (len(x_train)) + 1\n",
    "\n",
    "    # x_train_ = np.repeat(x_train, n_augmentations, axis=0)\n",
    "    # y_train_ = np.repeat(y_train, n_augmentations, axis=0)\n",
    "\n",
    "    print(\"augmenting the real data this many times: \", n_augmentations)\n",
    "    print(\"# data in real training data\", len(x_train))\n",
    "    x_train_augmented = []\n",
    "    y_train_augmented = []\n",
    "    for n_aug in tqdm(range(n_augmentations)):\n",
    "        x_train_temporary = augment_batch(\n",
    "            x_train,\n",
    "            sampling_func=sample_simple_augmentation_factors,\n",
    "            n_workers=5,\n",
    "            multiprocessing_on=True,\n",
    "        )\n",
    "        x_train_augmented.append(x_train_temporary)\n",
    "        y_train_augmented.append(y_train)\n",
    "    x_train = np.array(x_train_augmented)\n",
    "    y_train = np.array(y_train_augmented)\n",
    "\n",
    "    \"\"\"\n",
    "    Reshape so it fits to pytorch stuff\n",
    "    \"\"\"\n",
    "    x_train = x_train.reshape((-1, 1, x_train.shape[-2], x_train.shape[-1]))\n",
    "    y_train = y_train.reshape(-1)\n",
    "\n",
    "    idx = np.random.permutation(len(x_train))\n",
    "    x_train = x_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    x_train = x_train[:n_imgs_per_epoch]\n",
    "    y_train = y_train[:n_imgs_per_epoch]\n",
    "\n",
    "    print(\"# data in training data after augmentation\", len(x_train))\n",
    "    \"\"\"\n",
    "    Getting all parts ready for training\n",
    "    \"\"\"\n",
    "    dataset = StabilityDiagrams(imgs=x_train, labels=y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "        \"balanced\", [0, 1], y_train\n",
    "    )\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    net, optimizer, scheduler, criterion = get_net_optimiser_scheduler_criterion(\n",
    "        device, class_weights=class_weights\n",
    "    )\n",
    "    loss_history = []\n",
    "    lr_history = []\n",
    "    \"\"\"\n",
    "    Running the training\n",
    "    \"\"\"\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            X_train_minibatch = sample_batched[\"image\"].to(device).float()\n",
    "            y_train_minibatch = sample_batched[\"label\"].to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X_train_minibatch)\n",
    "            loss = criterion(outputs, y_train_minibatch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_history.append(loss.item())\n",
    "        lr_history.append(optimizer.param_groups[0][\"lr\"])\n",
    "        scheduler.step(loss.item())\n",
    "        if epoch % print_every_n_epoch == print_every_n_epoch - 1:\n",
    "            print(\"[%d] loss: %.7f\" % (epoch + 1, loss.item()))\n",
    "            print(\"learning rate now:\", optimizer.param_groups[0][\"lr\"])\n",
    "            net.eval()\n",
    "            outputs = net(torch.FloatTensor(x_test).to(device))\n",
    "            predicted = torch.max(outputs.data, 1).indices.detach().cpu()\n",
    "            print(confusion_matrix(y_test, predicted, labels=[0, 1]))\n",
    "            print(balanced_accuracy_score(y_test, predicted))\n",
    "            net.train()\n",
    "    path_networks = \"saved_networks/\"\n",
    "    os.makedirs(save_directory + path_networks, exist_ok=True)\n",
    "    torch.save(\n",
    "        net.state_dict(),\n",
    "        save_directory + path_networks + \"rep_\" + str(rep) + \".pth\",\n",
    "    )\n",
    "    net.eval()\n",
    "    outputs = net(torch.FloatTensor(x_test).to(device))\n",
    "    predicted = torch.max(outputs.data, 1).indices.detach().cpu()\n",
    "    print(confusion_matrix(y_test, predicted, labels=[0, 1]))\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    net.train()\n",
    "    print(\"#\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "    print(\"#\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxfk7fUP8S95",
    "outputId": "345eb915-e2c7-40b8-bcf7-8c2d8d81d9a6"
   },
   "source": [
    "# Now run it with all data \n",
    "\n",
    "\"testing\" on unaugmented original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HkOD6niOBSoh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4611, 48, 48)\n",
      "4611 train samples\n",
      "4611 test samples\n",
      "augmenting the real data this many times:  9\n",
      "# data in real training data 4611\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40606064f6548a18066d20d2ea740b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in training data after augmentation 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/torchenv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cdc4c147014d9dad16ba0d20b59f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] loss: 0.0378987\n",
      "learning rate now: 1e-05\n",
      "[[3744  141]\n",
      " [  81  645]]\n",
      "0.9260681578863397\n",
      "[66] loss: 0.0077767\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[3754  131]\n",
      " [  91  635]]\n",
      "0.9204681068317432\n",
      "[99] loss: 0.1195969\n",
      "learning rate now: 1.0000000000000004e-08\n",
      "[[3742  143]\n",
      " [  83  643]]\n",
      "0.9244333471606199\n",
      "[[3758  127]\n",
      " [  91  635]]\n",
      "0.9209829073465436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data prep\n",
    "\"\"\"\n",
    "\n",
    "# separate data into train and test datasetes\n",
    "x_train, x_test, y_train, y_test = X, X, y, y\n",
    "# Data preprocessing\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = normalise_arrays(x_train)\n",
    "x_test = normalise_arrays(x_test)\n",
    "# Scale labels to represent two clases (0,1)\n",
    "y_train = binarise(y_train)\n",
    "y_test = binarise(y_test)\n",
    "# Make sure images have shape (1, 48, 48) for pytorch\n",
    "\n",
    "x_test = np.expand_dims(x_test, 1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "y_test_this_rep = []\n",
    "\n",
    "\"\"\"\n",
    "Augmentation\n",
    "\n",
    "This might seem a bit involved but the reason is that the \n",
    "augmentation function augments each image in an array\n",
    "exactly once. We therefore repeat the augmentation a couple of times, enough\n",
    "so that we have enough data to match the ```n_imgs_per_epoch``` \n",
    "requirement.\n",
    "\"\"\"\n",
    "n_augmentations = n_imgs_per_epoch // (len(x_train)) + 1\n",
    "\n",
    "# x_train_ = np.repeat(x_train, n_augmentations, axis=0)\n",
    "# y_train_ = np.repeat(y_train, n_augmentations, axis=0)\n",
    "\n",
    "print(\"augmenting the real data this many times: \", n_augmentations)\n",
    "print(\"# data in real training data\", len(x_train))\n",
    "x_train_augmented = []\n",
    "y_train_augmented = []\n",
    "for n_aug in tqdm(range(n_augmentations)):\n",
    "    x_train_temporary = augment_batch(\n",
    "        x_train,\n",
    "        sampling_func=sample_simple_augmentation_factors,\n",
    "        n_workers=5,\n",
    "        multiprocessing_on=True,\n",
    "    )\n",
    "    x_train_augmented.append(x_train_temporary)\n",
    "    y_train_augmented.append(y_train)\n",
    "x_train = np.array(x_train_augmented)\n",
    "y_train = np.array(y_train_augmented)\n",
    "\n",
    "\"\"\"\n",
    "Reshape so it fits to pytorch stuff\n",
    "\"\"\"\n",
    "x_train = x_train.reshape((-1, 1, x_train.shape[-2], x_train.shape[-1]))\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "x_train = x_train[:n_imgs_per_epoch]\n",
    "y_train = y_train[:n_imgs_per_epoch]\n",
    "\n",
    "print(\"# data in training data after augmentation\", len(x_train))\n",
    "\"\"\"\n",
    "Getting all parts ready for training\n",
    "\"\"\"\n",
    "dataset = StabilityDiagrams(imgs=x_train, labels=y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "    \"balanced\", [0, 1], y_train\n",
    ")\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "net, optimizer, scheduler, criterion = get_net_optimiser_scheduler_criterion(\n",
    "    device, class_weights=class_weights\n",
    ")\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "\"\"\"\n",
    "Running the training\n",
    "\"\"\"\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        X_train_minibatch = sample_batched[\"image\"].to(device).float()\n",
    "        y_train_minibatch = sample_batched[\"label\"].to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train_minibatch)\n",
    "        loss = criterion(outputs, y_train_minibatch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_history.append(loss.item())\n",
    "    lr_history.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step(loss.item())\n",
    "    if epoch % print_every_n_epoch == print_every_n_epoch - 1:\n",
    "        print(\"[%d] loss: %.7f\" % (epoch + 1, loss.item()))\n",
    "        print(\"learning rate now:\", optimizer.param_groups[0][\"lr\"])\n",
    "        net.eval()\n",
    "        outputs = net(torch.FloatTensor(x_test).to(device))\n",
    "        predicted = torch.max(outputs.data, 1).indices.detach().cpu()\n",
    "        print(confusion_matrix(y_test, predicted, labels=[0, 1]))\n",
    "        print(balanced_accuracy_score(y_test, predicted))\n",
    "        net.train()\n",
    "path_networks = \"saved_networks/\"\n",
    "os.makedirs(save_directory + path_networks, exist_ok=True)\n",
    "torch.save(\n",
    "    net.state_dict(),\n",
    "    save_directory + path_networks + \"all_data.pth\",\n",
    ")\n",
    "net.eval()\n",
    "outputs = net(torch.FloatTensor(x_test).to(device))\n",
    "predicted = torch.max(outputs.data, 1).indices.detach().cpu()\n",
    "print(confusion_matrix(y_test, predicted, labels=[0, 1]))\n",
    "print(balanced_accuracy_score(y_test, predicted))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DDclassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045ae99b2e6d4526ae7756da97a1257b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e3805f558634820aba6d365aa3f497d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a05de4333f2d45178e866ce5f68ca2f7",
      "value": "100%"
     }
    },
    "0d41aacd5b8f4bbe9354db9a94e9d072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21318c6241ee4fca923d3e28575dd265": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27b79a8c11444b3496b89d8e29aea4ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e3805f558634820aba6d365aa3f497d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32b61b082ddb484f8beef1828d17ad5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e632beb2024409ebe5a2db857497aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc42c31622244a8bab98dfc447b2d20c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_27b79a8c11444b3496b89d8e29aea4ff",
      "value": " 44%"
     }
    },
    "503564688db645eba4ea5d61374dd527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52a8971b7c8946588c002a4b58ef8ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee987668e76545d189b32c56aeadf33f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_503564688db645eba4ea5d61374dd527",
      "value": " 21/21 [30:17&lt;00:00, 86.79s/it]"
     }
    },
    "549d601f29594b309be96c88b54b6364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54d8c9a16a1f4f24b03e02b5feecf246": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6667f96a66e444b58a8f9ba5c00d129c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ba6f2aa665d439dac3e5c3739997646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_045ae99b2e6d4526ae7756da97a1257b",
       "IPY_MODEL_940061db8c674f39b0e5efdac1061759",
       "IPY_MODEL_52a8971b7c8946588c002a4b58ef8ab3"
      ],
      "layout": "IPY_MODEL_54d8c9a16a1f4f24b03e02b5feecf246"
     }
    },
    "8efc0d2243b447e7b6c2c45037b3bd40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6667f96a66e444b58a8f9ba5c00d129c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0d41aacd5b8f4bbe9354db9a94e9d072",
      "value": " 44/100 [1:32:26&lt;1:57:24, 125.80s/it]"
     }
    },
    "940061db8c674f39b0e5efdac1061759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ad8beaf0cd436b86fb921b33074087",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21318c6241ee4fca923d3e28575dd265",
      "value": 21
     }
    },
    "a05de4333f2d45178e866ce5f68ca2f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2ad8beaf0cd436b86fb921b33074087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51bc7fd908041479b62f13db0e023e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc42c31622244a8bab98dfc447b2d20c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee987668e76545d189b32c56aeadf33f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1997a9ea1bb4ef1b7b781b09dee326b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_549d601f29594b309be96c88b54b6364",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a51bc7fd908041479b62f13db0e023e8",
      "value": 44
     }
    },
    "f84fec6c01da486e9d8d4c84f8656808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e632beb2024409ebe5a2db857497aba",
       "IPY_MODEL_f1997a9ea1bb4ef1b7b781b09dee326b",
       "IPY_MODEL_8efc0d2243b447e7b6c2c45037b3bd40"
      ],
      "layout": "IPY_MODEL_32b61b082ddb484f8beef1828d17ad5b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
